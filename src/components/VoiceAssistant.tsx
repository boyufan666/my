import { useState, useEffect, useRef, useCallback } from 'react';
import { motion } from 'motion/react';
import { Mic, MicOff, Volume2, VolumeX } from 'lucide-react';
import { VoiceRecognition, VoiceSynthesis } from '../lib/voice';

// å¯¼å‡ºé™æ€æ–¹æ³•ä¾›ç»„ä»¶ä½¿ç”¨
const checkNetworkConnection = () => {
  if (typeof navigator !== 'undefined' && 'onLine' in navigator) {
    return navigator.onLine;
  }
  return true;
};
import { sendChatMessage, startMMSEAssessment } from '../lib/api';
import { AIAssistant } from './AIAssistant';
import { Button } from './ui/button';
import { toast } from 'sonner';

interface VoiceAssistantProps {
  onNavigate?: (page: string, gameId?: string) => void;
  onCommand?: (command: string) => void;
  autoStart?: boolean;
  mmseMode?: boolean;
  onMMSEComplete?: (score: number) => void;
}

export function VoiceAssistant({
  onNavigate,
  onCommand,
  autoStart = false,
  mmseMode = false,
  onMMSEComplete,
}: VoiceAssistantProps) {
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [conversation, setConversation] = useState<Array<{ role: 'user' | 'assistant'; content: string }>>([]);
  const [sessionId] = useState(() => `session_${Date.now()}`);
  const [currentMMSEIndex, setCurrentMMSEIndex] = useState(-1);
  const [mmseStarted, setMmseStarted] = useState(false);

  const recognitionRef = useRef<VoiceRecognition | null>(null);
  const synthesisRef = useRef<VoiceSynthesis | null>(null);

  useEffect(() => {
    recognitionRef.current = new VoiceRecognition();
    synthesisRef.current = new VoiceSynthesis();

    if (autoStart && !mmseMode) {
      // è‡ªåŠ¨å¼€å§‹å¯¹è¯
      setTimeout(() => {
        handleStartConversation();
      }, 1000);
    }

    return () => {
      recognitionRef.current?.stop();
      synthesisRef.current?.stop();
    };
  }, [autoStart, mmseMode]);

  // è¯·æ±‚éº¦å…‹é£æƒé™
  const requestMicrophonePermission = useCallback(async (): Promise<boolean> => {
    try {
      // å…ˆæ£€æŸ¥æƒé™çŠ¶æ€
      if (navigator.permissions) {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        if (permissionStatus.state === 'granted') {
          console.log('âœ… éº¦å…‹é£æƒé™å·²æˆäºˆ');
          return true;
        }
        if (permissionStatus.state === 'denied') {
          toast.error('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£');
          return false;
        }
      }

      // å°è¯•è¯·æ±‚æƒé™ï¼ˆé€šè¿‡getUserMediaï¼‰
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      // ç«‹å³åœæ­¢æµï¼Œæˆ‘ä»¬åªéœ€è¦æƒé™
      stream.getTracks().forEach(track => track.stop());
      console.log('âœ… éº¦å…‹é£æƒé™å·²è·å–');
      toast.success('éº¦å…‹é£æƒé™å·²æˆäºˆ');
      return true;
    } catch (error: any) {
      console.error('âŒ è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error);
      let errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£';
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
      } else if (error.name === 'NotReadableError') {
        errorMessage = 'éº¦å…‹é£è¢«å…¶ä»–åº”ç”¨å ç”¨';
      }
      toast.error(errorMessage);
      return false;
    }
  }, []);

  const handleStartConversation = useCallback(async () => {
    // å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
    const hasPermission = await requestMicrophonePermission();
    if (!hasPermission) {
      toast.error('éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½å¼€å§‹è¯„ä¼°ï¼Œè¯·å…è®¸è®¿é—®éº¦å…‹é£');
      return;
    }

    const greeting = mmseMode
      ? 'æ‚¨å¥½ï¼ç°åœ¨å¼€å§‹è¿›è¡Œç®€æ˜“æ™ºåŠ›çŠ¶æ€æ£€æŸ¥ã€‚æˆ‘ä¼šé—®æ‚¨ä¸€äº›ç®€å•çš„é—®é¢˜ï¼Œè¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µå›ç­”ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼'
      : 'æ‚¨å¥½ï¼Œæˆ‘æ˜¯å°å¿†ï¼Œæ‚¨çš„æ™ºèƒ½åº·å¤åŠ©æ‰‹ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ';

    setConversation([{ role: 'assistant', content: greeting }]);
    // ä½¿ç”¨æ¸©æŸ”å¥³å£°æ’­æ”¾
    synthesisRef.current?.speak(greeting, { rate: 0.9, pitch: 1.1, volume: 0.9 });

    if (mmseMode && !mmseStarted) {
      try {
        console.log('ğŸš€ æ­£åœ¨å¯åŠ¨MMSEè¯„ä¼°...');
        const response = await startMMSEAssessment(sessionId);
        console.log('âœ… MMSEè¯„ä¼°å¯åŠ¨å“åº”:', response);
        
        if (response.success) {
          setMmseStarted(true);
          setCurrentMMSEIndex(0);
          const firstQuestion = response.data.first_question;
          setConversation(prev => [...prev, { role: 'assistant', content: firstQuestion }]);
          // ä½¿ç”¨æ¸©æŸ”å¥³å£°æ’­æ”¾ç¬¬ä¸€ä¸ªé—®é¢˜
          synthesisRef.current?.speak(firstQuestion, { rate: 0.9, pitch: 1.1, volume: 0.9 });
          toast.success('è¯„ä¼°å·²å¼€å§‹');
        } else {
          toast.error('å¯åŠ¨è¯„ä¼°å¤±è´¥ï¼šæœåŠ¡å™¨è¿”å›å¤±è´¥');
        }
      } catch (error: any) {
        console.error('âŒ å¯åŠ¨è¯„ä¼°å¤±è´¥:', error);
        let errorMessage = 'å¯åŠ¨è¯„ä¼°å¤±è´¥ï¼Œè¯·é‡è¯•';
        if (error.message) {
          errorMessage = `å¯åŠ¨è¯„ä¼°å¤±è´¥: ${error.message}`;
        } else if (error instanceof TypeError && error.message.includes('fetch')) {
          errorMessage = 'æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
        }
        toast.error(errorMessage);
      }
    }
  }, [mmseMode, mmseStarted, sessionId, requestMicrophonePermission]);

  // å…ˆå®šä¹‰handleStartListeningï¼Œé¿å…å¾ªç¯ä¾èµ–
  const handleStartListening = useCallback(async () => {
    if (!recognitionRef.current) {
      toast.error('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
      return;
    }

    // æ£€æŸ¥ç½‘ç»œè¿æ¥
    if (!checkNetworkConnection()) {
      toast.error('ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•');
      return;
    }

    // å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
    const hasPermission = await requestMicrophonePermission();
    if (!hasPermission) {
      toast.error('éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½è¿›è¡Œè¯­éŸ³è¯†åˆ«');
      return;
    }

    if (isSpeaking) {
      synthesisRef.current?.stop();
      setIsSpeaking(false);
    }

    setIsListening(true);
    try {
      recognitionRef.current.start(
        (text: string) => {
          // æœ€ç»ˆç»“æœ - ç«‹å³å¤„ç†
          console.log('âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ:', text);
          handleVoiceResult(text);
        },
        (error: string) => {
          setIsListening(false);
          console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
          
          // ç½‘ç»œç›¸å…³é”™è¯¯
          if (error.includes('ç½‘ç»œ') || error.includes('network')) {
            toast.error('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•');
            // è‡ªåŠ¨é‡è¯•
            setTimeout(() => {
              if (!isListening) {
                handleStartListening();
              }
            }, 2000);
          } else if (error !== 'no-speech' && error !== 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•') {
            toast.error(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${error}`);
          }
        },
        (interimText: string) => {
          // ä¸´æ—¶ç»“æœ - å®æ—¶æ˜¾ç¤ºè¯†åˆ«è¿‡ç¨‹
          console.log('ğŸ”„ å®æ—¶è¯†åˆ«:', interimText);
        }
      );
    } catch (error: any) {
      console.error('âŒ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      setIsListening(false);
      
      // ç½‘ç»œé”™è¯¯è‡ªåŠ¨é‡è¯•
      if (error.message && (error.message.includes('ç½‘ç»œ') || error.message.includes('fetch'))) {
        toast.error('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œ2ç§’åè‡ªåŠ¨é‡è¯•...');
        setTimeout(() => {
          if (!isListening) {
            handleStartListening();
          }
        }, 2000);
      } else {
        toast.error(`å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message || 'æœªçŸ¥é”™è¯¯'}`);
      }
    }
  }, [isSpeaking, requestMicrophonePermission, isListening]);

  const handleVoiceResult = useCallback(async (text: string) => {
    if (!text.trim()) return;

    const userMessage = text.trim();
    setConversation(prev => [...prev, { role: 'user', content: userMessage }]);
    setIsListening(false);

    // å¤„ç†è¯­éŸ³å‘½ä»¤ï¼ˆä»…åœ¨éMMSEæ¨¡å¼ä¸‹ï¼‰
    if (!mmseMode && onCommand) {
      onCommand(userMessage);
    }

    // å¤„ç†å¯¼èˆªå‘½ä»¤ï¼ˆä»…åœ¨éMMSEæ¨¡å¼ä¸‹ï¼Œé¿å…æ‰“æ–­è¯„ä¼°æµç¨‹ï¼‰
    if (!mmseMode && onNavigate) {
      const lowerText = userMessage.toLowerCase();
      if (lowerText.includes('é¦–é¡µ') || lowerText.includes('ä¸»é¡µ')) {
        onNavigate('game-main');
        return;
      }
      if (lowerText.includes('æ¸¸æˆåº“') || lowerText.includes('æ¸¸æˆ')) {
        onNavigate('game-library');
        return;
      }
      if (lowerText.includes('æ•°æ®ä¸­å¿ƒ') || lowerText.includes('æ•°æ®')) {
        onNavigate('data-center');
        return;
      }
      if (lowerText.includes('ä¸ªäººä¸­å¿ƒ') || lowerText.includes('æˆ‘çš„')) {
        onNavigate('profile');
        return;
      }
      if (lowerText.includes('ç¤¾äº¤') || lowerText.includes('å®¶äºº')) {
        onNavigate('social-center');
        return;
      }
    }

    // æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    const loadingMessage = { role: 'assistant' as const, content: 'æ­£åœ¨æ€è€ƒ...' };
    setConversation(prev => [...prev, loadingMessage]);

    try {
      // ä½¿ç”¨å¢å¼ºçš„ç½‘ç»œè¿æ¥ï¼ˆå¸¦é‡è¯•å’Œè¶…æ—¶ï¼‰
      const response = await sendChatMessage(
        userMessage,
        sessionId,
        mmseMode && currentMMSEIndex >= 0,
        currentMMSEIndex,
        3, // é‡è¯•3æ¬¡
        30000 // 30ç§’è¶…æ—¶
      );

      // ç§»é™¤åŠ è½½æ¶ˆæ¯
      setConversation(prev => prev.filter(msg => msg !== loadingMessage));

      if (response.success) {
        const reply = response.data.reply;
        
        // ç¡®ä¿å›å¤ä¸ä¸ºç©º
        if (!reply || !reply.trim()) {
          throw new Error('AIå›å¤ä¸ºç©º');
        }

        setConversation(prev => [...prev, { role: 'assistant', content: reply }]);

        // è¯­éŸ³æ’­æ”¾å›å¤ï¼ˆæ¸©æŸ”å¥³å£°ï¼‰
        setIsSpeaking(true);
        const speakOptions = {
          rate: 0.9, // ç¨æ…¢ï¼Œæ›´æ¸©æŸ”
          pitch: 1.1, // ç¨é«˜ï¼Œæ›´å¥³æ€§åŒ–
          volume: 0.9, // é€‚ä¸­éŸ³é‡
        };

        // ä½¿ç”¨å¸¦å›è°ƒçš„speakæ–¹æ³•
        synthesisRef.current?.speak(reply, speakOptions, () => {
          setIsSpeaking(false);
          
          // éMMSEæ¨¡å¼ä¸‹ï¼Œè¯´å®Œåè‡ªåŠ¨å¼€å§‹ä¸‹ä¸€è½®ç›‘å¬
          if (!mmseMode) {
            setTimeout(() => {
              if (!isListening) {
                handleStartListening();
              }
            }, 500);
          }
        });

        // MMSE æ¨¡å¼å¤„ç†
        if (response.data.isMMSE) {
          setCurrentMMSEIndex(response.data.currentMMSEIndex);
          // MMSEæ¨¡å¼ä¸‹ï¼Œè¯´å®Œé—®é¢˜åè‡ªåŠ¨å¼€å§‹ç›‘å¬
          setTimeout(() => {
            if (!isListening) {
              handleStartListening();
            }
          }, 500);
        } else if (mmseMode && currentMMSEIndex >= 0 && !response.data.isMMSE) {
          // MMSE è¯„ä¼°å®Œæˆ
          setCurrentMMSEIndex(-1);
          if (onMMSEComplete) {
            // ä»å›å¤ä¸­æå–åˆ†æ•°ï¼ˆç®€å•è§£æï¼‰
            const scoreMatch = reply.match(/(\d+)\/30åˆ†/);
            if (scoreMatch) {
              onMMSEComplete(parseInt(scoreMatch[1], 10));
            }
          }
        }
      } else {
        throw new Error('æœåŠ¡å™¨è¿”å›å¤±è´¥');
      }
    } catch (error: any) {
      // ç§»é™¤åŠ è½½æ¶ˆæ¯
      setConversation(prev => prev.filter(msg => msg !== loadingMessage));
      
      console.error('âŒ å‘é€æ¶ˆæ¯å¤±è´¥:', error);
      
      let errorMessage = 'å‘é€æ¶ˆæ¯å¤±è´¥ï¼Œè¯·é‡è¯•';
      if (error.message) {
        if (error.message.includes('è¶…æ—¶')) {
          errorMessage = 'ç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•';
        } else if (error.message.includes('fetch') || error.message.includes('ç½‘ç»œ')) {
          errorMessage = 'ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
        } else {
          errorMessage = `å‘é€æ¶ˆæ¯å¤±è´¥: ${error.message}`;
        }
      }
      
      toast.error(errorMessage);
      
      // æ·»åŠ é”™è¯¯æç¤ºåˆ°å¯¹è¯
      setConversation(prev => [...prev, { 
        role: 'assistant', 
        content: 'æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·å†è¯´ä¸€éå¥½å—ï¼Ÿ' 
      }]);
      
      // æ’­æ”¾é”™è¯¯æç¤ºè¯­éŸ³
      setIsSpeaking(true);
      synthesisRef.current?.speak('æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·å†è¯´ä¸€éå¥½å—ï¼Ÿ', {
        rate: 0.9,
        pitch: 1.1,
        volume: 0.9
      }, () => {
        setIsSpeaking(false);
        // è‡ªåŠ¨é‡æ–°å¼€å§‹ç›‘å¬
        setTimeout(() => {
          if (!isListening) {
            handleStartListening();
          }
        }, 1000);
      });
    }
  }, [sessionId, mmseMode, currentMMSEIndex, onNavigate, onCommand, onMMSEComplete, isListening, handleStartListening]);


  const handleStopListening = useCallback(() => {
    recognitionRef.current?.stop();
    setIsListening(false);
  }, []);

  return (
    <div className="flex flex-col items-center gap-4">
      <AIAssistant size="large" showWave={isListening || isSpeaking} />

      {/* å¯¹è¯å†å² */}
      {conversation.length > 0 && (
        <div className="w-full max-w-md space-y-2 max-h-64 overflow-y-auto">
          {conversation.map((msg, index) => (
            <motion.div
              key={index}
              initial={{ opacity: 0, y: 10 }}
              animate={{ opacity: 1, y: 0 }}
              className={`p-3 rounded-2xl ${
                msg.role === 'user'
                  ? 'bg-purple-500 text-white ml-auto max-w-[80%]'
                  : 'bg-purple-100 text-gray-800 mr-auto max-w-[80%]'
              }`}
            >
              <p className="text-sm">{msg.content}</p>
            </motion.div>
          ))}
        </div>
      )}

      {/* æ§åˆ¶æŒ‰é’® */}
      <div className="flex gap-4 items-center">
        {!mmseStarted && mmseMode && (
          <Button
            onClick={handleStartConversation}
            className="bg-gradient-to-r from-purple-500 to-pink-500"
          >
            å¼€å§‹è¯„ä¼°
          </Button>
        )}

        {!isListening ? (
          <Button
            onClick={handleStartListening}
            className="w-16 h-16 rounded-full bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600"
          >
            <Mic size={24} className="text-white" />
          </Button>
        ) : (
          <Button
            onClick={handleStopListening}
            className="w-16 h-16 rounded-full bg-red-500 hover:bg-red-600"
          >
            <MicOff size={24} className="text-white" />
          </Button>
        )}

        {isSpeaking && (
          <Button
            onClick={() => {
              synthesisRef.current?.stop();
              setIsSpeaking(false);
            }}
            variant="outline"
            className="w-16 h-16 rounded-full"
          >
            <VolumeX size={24} />
          </Button>
        )}
      </div>

      {/* çŠ¶æ€æç¤º */}
      <p className="text-sm text-gray-600 text-center">
        {isListening && 'æ­£åœ¨è†å¬...'}
        {isSpeaking && 'æ­£åœ¨æ’­æ”¾å›å¤...'}
        {!isListening && !isSpeaking && 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹å¯¹è¯'}
      </p>
    </div>
  );
}

